{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7716d1cc",
   "metadata": {},
   "source": [
    "# Pipeline: Bronze -> Silver\n",
    "\n",
    "## Instruções e informações\n",
    "\n",
    "### Objetivo:  \n",
    "\n",
    "Nesta fase, realizamos um processo de **extração, limpeza e transformação** dos dados:\n",
    "\n",
    "- **Extração:** carregamento de arquivos CSV brutos provenientes de diferentes fontes.  \n",
    "- **Limpeza:** tratamento de valores faltantes, padronização de tipos e formatos, correção de inconsistências.  \n",
    "- **Transformação:** aplicação de regras de negócio, filtros, agregações e organização dos dados de forma estruturada para análise.  \n",
    "\n",
    "### Configuração Inicial\n",
    "\n",
    "Esta seção realiza a configuração inicial de todo o ambiente que será utilizado nas análises subsequentes, incluindo:  \n",
    "\n",
    "- Importação das bibliotecas necessárias (ex.: `pandas`, `numpy`, `matplotlib`, `seaborn`), explicando a função de cada uma na sequência de transformações.  \n",
    "- Definição dos caminhos para os arquivos de dados brutos (CSV da camada Bronze) que serão processados.  \n",
    "- Identificação de metadados relevantes que podem ser úteis para a limpeza e análise, como tipos de colunas, valores nulos, formatos de data, etc.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da0a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando: circuits.csv...\n",
      "  -> Total de 77 registros carregados.\n",
      "Carregando: constructor_results.csv...\n",
      "  -> Total de 12625 registros carregados.\n",
      "Carregando: constructor_standings.csv...\n",
      "  -> Total de 13391 registros carregados.\n",
      "Carregando: constructors.csv...\n",
      "  -> Total de 212 registros carregados.\n",
      "Carregando: driver_standings.csv...\n",
      "  -> Total de 34863 registros carregados.\n",
      "Carregando: drivers.csv...\n",
      "  -> Total de 861 registros carregados.\n",
      "Carregando: lap_times.csv...\n",
      "  -> Total de 589081 registros carregados.\n",
      "Carregando: pit_stops.csv...\n",
      "  -> Total de 11371 registros carregados.\n",
      "Carregando: qualifying.csv...\n",
      "  -> Total de 10494 registros carregados.\n",
      "Carregando: races.csv...\n",
      "  -> Total de 1125 registros carregados.\n",
      "Carregando: results.csv...\n",
      "  -> Total de 26759 registros carregados.\n",
      "Carregando: seasons.csv...\n",
      "  -> Total de 75 registros carregados.\n",
      "Carregando: sprint_results.csv...\n",
      "  -> Total de 360 registros carregados.\n",
      "Carregando: status.csv...\n",
      "  -> Total de 139 registros carregados.\n",
      "\n",
      "--- Carregamento Concluído ---\n",
      "DataFrames disponíveis no dicionário 'df_bronze': ['circuits', 'constructor_results', 'constructor_standings', 'constructors', 'driver_standings', 'drivers', 'lap_times', 'pit_stops', 'qualifying', 'races', 'results', 'seasons', 'sprint_results', 'status']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 1. Definições de Caminho e Arquivos ---\n",
    "\n",
    "BASE_PATH = '../data/bronze_raw/' \n",
    "\n",
    "file_names = [\n",
    "    'circuits.csv',\n",
    "    'constructor_results.csv',\n",
    "    'constructor_standings.csv',\n",
    "    'constructors.csv',\n",
    "    'driver_standings.csv',\n",
    "    'drivers.csv',\n",
    "    'lap_times.csv',\n",
    "    'pit_stops.csv',\n",
    "    'qualifying.csv',\n",
    "    'races.csv',\n",
    "    'results.csv',\n",
    "    'seasons.csv',\n",
    "    'sprint_results.csv',\n",
    "    'status.csv'\n",
    "]\n",
    "\n",
    "df_bronze = {}\n",
    "\n",
    "# --- 2. Função de Carregamento e Tratamento Inicial ---\n",
    "\n",
    "def load_bronze_data(file_name):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo CSV da Camada Bronze, substituindo '\\\\N' por NaN \n",
    "    e forçando a leitura de IDs como string para evitar problemas de tipo.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(BASE_PATH, file_name)\n",
    "    print(f\"Carregando: {file_name}...\")\n",
    "    \n",
    "    # Define as chaves comuns que devem ser lidas como strings (object)\n",
    "    dtype_map = {\n",
    "        col: 'object' for col in ['driverId', 'raceId', 'constructorId', 'statusId', 'circuitId'] \n",
    "        if col in pd.read_csv(file_path, nrows=0).columns\n",
    "    }\n",
    "    \n",
    "    df = pd.read_csv(\n",
    "        file_path, \n",
    "        na_values=['\\\\N'], \n",
    "        dtype=dtype_map,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    print(f\"  -> Total de {len(df)} registros carregados.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 3. Execução do Carregamento ---\n",
    "\n",
    "for file in file_names:\n",
    "    # A chave do dicionário será o nome do arquivo sem a extensão '.csv'\n",
    "    df_name = file.replace('.csv', '')\n",
    "    try:\n",
    "        df_bronze[df_name] = load_bronze_data(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRO: Arquivo {file} não encontrado no caminho {BASE_PATH}. Pulando.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao carregar {file}: {e}\")\n",
    "        \n",
    "print(\"\\n--- Carregamento Concluído ---\")\n",
    "print(f\"DataFrames disponíveis no dicionário 'df_bronze': {list(df_bronze.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d414b",
   "metadata": {},
   "source": [
    "___\n",
    "## Processo de Transformação para a Camada SILVER\n",
    "\n",
    "Este notebook documenta a etapa de transformação de dados para o **Modelo Dimensional da Camada Silver**, sucedendo a ingestão de 14 arquivos CSV da base de dados de Fórmula 1 (Ergast) na Camada Bronze. Os dados brutos, preservados com granularidade transacional por corrida, piloto ou volta, são lidos integralmente e reestruturados para análise otimizada. As transformações essenciais incluem a desnormalização de atributos descritivos em **Dimensões coerentes** (`DIM_PILOTO`, `DIM_CORRIDA`, `DIM_CONSTRUTOR`), a criação e atribuição de **Chaves Substitutas (`_sk_`)** para todas as dimensões, e a consolidação de diferentes fontes de resultados (`results.csv`, `sprint_results.csv`, `constructor_results.csv`, `driver_standings.csv`, `constructor_standings.csv`) em Tabelas Fato específicas (`FATO_RESULTADOS_CORRIDA`, `FATO_POSICOES_CAMPEONATO`), promovendo uma visão unificada da performance.\n",
    "\n",
    "Do ponto de vista de modelagem, adota-se o esquema Estrela/Snowflake com granularidade por resultado de corrida/piloto e por posição de campeonato. A transformação de chaves naturais (`driverId`, `raceId`) em chaves substitutas (`piloto_sk`, `corrida_sk`) otimiza as operações de *join* e permite a manutenção de histórico de atributos (SCD - Slowly Changing Dimensions). A ligação entre fatos e dimensões é padronizada via `_sk_` (e.g., `FATO_RESULTADOS_CORRIDA` liga-se à `DIM_PILOTO` via `#piloto_sk`), exceto pelo `#qualifyId`, que é mantido como **Dimensão Degenerada (DD)** no Fato, fornecendo o identificador único da qualificação diretamente no registro de resultado da corrida, o que viabiliza um Drill-Through preciso para os tempos de Q1/Q2/Q3 da Camada Bronze.\n",
    "\n",
    "A governança do processo é assegurada pela preservação das **chaves naturais originais (`#Id`)** em todas as dimensões da Silver, garantindo a rastreabilidade completa e a capacidade de auditoria (*Drill-Through*) de volta para a Camada Bronze, em conformidade com a arquitetura Medallion. A tipagem explícita dos dados e a criação de campos derivados (como `nome_completo` na `DIM_PILOTO` ou o *flag* `is_sprint` no Fato) evitam ambiguidades e enriquecem o contexto analítico. Ao final, o resultado é materializado nas tabelas Fato e Dimensão com um modelo otimizado, prontas para serem consumidas por rotinas de agregação (na Camada Gold) e ferramentas de BI, estabelecendo uma base sólida para monitoramento perene da performance e resultados da Fórmula 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c2967",
   "metadata": {},
   "source": [
    "## Iniciando as Tabelas Fato\n",
    "\n",
    "Esta seção da Camada Silver foca na criação das duas principais tabelas fato analíticas. Primeiramente, a `FATO_RESULTADOS_CORRIDA` é construída pela união dos resultados de Grandes Prêmios e Corridas Sprint, e é enriquecida com o `qualifyId` (Dimensão Degenerada). Em seguida, a `FATO_POSICOES_CAMPEONATO` é criada consolidando os rankings de pilotos e construtores. Ambas as tabelas recebem um padrão de nomenclatura em português, têm suas colunas tipadas corretamente e utilizam as chaves naturais da Camada Bronze como referência temporária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ef6511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Criando FATO_RESULTADOS_CORRIDA...\n",
      "2. Criando FATO_PONTUACAO_CAMPEONATO...\n",
      "\n",
      "--- Criação das Tabelas Fato da Camada Silver Concluída ---\n",
      "FATO_RESULTADOS_CORRIDA: 27119 registros\n",
      "FATO_PONTUACAO_CAMPEONATO: 48254 registros\n",
      "Os DataFrames estão disponíveis no dicionário 'df_silver'.\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que o dicionário df_bronze foi carregado corretamente.\n",
    "\n",
    "if 'df_bronze' not in locals() or not df_bronze:\n",
    "    print(\"ERRO: O dicionário 'df_bronze' não foi encontrado ou está vazio. Por favor, execute a célula de carregamento da Camada Bronze primeiro.\")\n",
    "else:\n",
    "    \n",
    "    # --- 1. CRIAÇÃO DA FATO_RESULTADOS_CORRIDA ---\n",
    "    \n",
    "    print(\"1. Criando FATO_RESULTADOS_CORRIDA...\")\n",
    "    \n",
    "    # 1.1 Preparar resultados de GP (results)\n",
    "    df_results_gp = df_bronze['results'].copy()\n",
    "    df_results_gp['is_sprint'] = 0  # Flag: 0 = Grande Prêmio\n",
    "    \n",
    "    # 1.2 Preparar resultados de Sprint (sprint_results)\n",
    "    df_results_sprint = df_bronze['sprint_results'].copy()\n",
    "    df_results_sprint['is_sprint'] = 1  # Flag: 1 = Corrida Sprint\n",
    "    \n",
    "    # CORREÇÃO CRÍTICA: Adicionar colunas ausentes no Sprint para que a concatenação funcione.\n",
    "    missing_cols_in_sprint = ['rank', 'fastestLapSpeed', 'time', 'fastestLapTime']\n",
    "    for col in missing_cols_in_sprint:\n",
    "        if col not in df_results_sprint.columns:\n",
    "            df_results_sprint[col] = np.nan\n",
    "            \n",
    "    # 1.3 Definir colunas comuns para concatenação e renomear para o padrão Silver (BRZ_ID)\n",
    "    cols_to_keep = [\n",
    "        'resultId', 'raceId', 'driverId', 'constructorId', 'statusId', \n",
    "        'grid', 'positionOrder', 'points', 'laps', \n",
    "        'milliseconds', 'fastestLap', 'rank', 'fastestLapSpeed', \n",
    "        'position', 'time', 'fastestLapTime', \n",
    "        'is_sprint'\n",
    "    ]\n",
    "    \n",
    "    df_results_gp = df_results_gp[cols_to_keep].rename(columns={'resultId': 'resultado_brz_id'})\n",
    "    df_results_sprint = df_results_sprint[cols_to_keep].rename(columns={'resultId': 'resultado_brz_id'})\n",
    "    \n",
    "    df_fato_resultados = pd.concat([df_results_gp, df_results_sprint], ignore_index=True)\n",
    "    \n",
    "    # 1.4 Adicionar a Dimensão Degenerada (DD): qualifyId\n",
    "    df_qualifying = df_bronze['qualifying'][['raceId', 'driverId', 'qualifyId']].copy()\n",
    "    \n",
    "    # Merge para trazer o qualifyId (DD).\n",
    "    df_fato_resultados = pd.merge(\n",
    "        df_fato_resultados,\n",
    "        df_qualifying,\n",
    "        on=['raceId', 'driverId'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 1.5 Renomeação e Mapeamento para o Fato Silver (Seguindo o MER)\n",
    "    df_fato_resultados = df_fato_resultados.rename(columns={\n",
    "        # Chaves estrangeiras (temporariamente BRZ IDs) e DD\n",
    "        'raceId': '#corrida_sk',\n",
    "        'driverId': '#piloto_sk',\n",
    "        'constructorId': '#construtor_sk',\n",
    "        'statusId': '#status_sk',\n",
    "        'qualifyId': '#qualificacao_sk', # Usando o nome da SK para fins de mapeamento final\n",
    "        \n",
    "        # Atributos e Métricas\n",
    "        'grid': '#grid',\n",
    "        'rank': '#rank',\n",
    "        'points': 'pontos',\n",
    "        'positionOrder': 'posicao_final_ordenada',\n",
    "        'laps': 'voltas_completadas',\n",
    "        'milliseconds': 'tempo_total_ms',\n",
    "        'fastestLap': 'volta_mais_rapida', # Número da volta mais rápida\n",
    "        'fastestLapSpeed': 'velocidade_maxima',\n",
    "        \n",
    "        # Outras colunas\n",
    "        'resultado_brz_id': 'resultado_brz_id_auditoria'\n",
    "    }).drop(columns=['position', 'time', 'fastestLapTime'])\n",
    "    \n",
    "    # 1.6 Tipagem de Colunas\n",
    "    numeric_cols = [\n",
    "        'posicao_final_ordenada', 'pontos', 'tempo_total_ms', 'voltas_completadas', \n",
    "        'volta_mais_rapida', '#rank', 'velocidade_maxima', '#grid', 'is_sprint'\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in df_fato_resultados.columns:\n",
    "            df_fato_resultados[col] = pd.to_numeric(df_fato_resultados[col], errors='coerce')\n",
    "    \n",
    "    # 1.7 Adicionar Chave Substituta (SK)\n",
    "    df_fato_resultados['resultado_sk'] = range(1, len(df_fato_resultados) + 1)\n",
    "    \n",
    "    # 1.8 Selecionar e reordenar colunas finais para o Fato\n",
    "    FATO_RESULTADOS_COLS = [\n",
    "        'resultado_sk', '#corrida_sk', '#piloto_sk', '#construtor_sk', '#status_sk', \n",
    "        '#qualificacao_sk', '#grid', '#rank', 'pontos', 'posicao_final_ordenada', \n",
    "        'voltas_completadas', 'tempo_total_ms', 'volta_mais_rapida', 'velocidade_maxima', \n",
    "        'is_sprint', 'resultado_brz_id_auditoria'\n",
    "    ]\n",
    "    df_fato_resultados = df_fato_resultados[[col for col in FATO_RESULTADOS_COLS if col in df_fato_resultados.columns]].copy()\n",
    "    \n",
    "    \n",
    "    # --- 2. CRIAÇÃO DA FATO_PONTUACAO_CAMPEONATO ---\n",
    "    \n",
    "    print(\"2. Criando FATO_PONTUACAO_CAMPEONATO...\")\n",
    "\n",
    "    # 2.1 Preparar Standings de Pilotos\n",
    "    df_driver_standings = df_bronze['driver_standings'].copy()\n",
    "    df_driver_standings['constructorId'] = np.nan # Preenche coluna de Construtor\n",
    "    \n",
    "    # 2.2 Preparar Standings de Construtores\n",
    "    df_constructor_standings = df_bronze['constructor_standings'].copy()\n",
    "    df_constructor_standings['driverId'] = np.nan # Preenche coluna de Piloto\n",
    "    \n",
    "    # 2.3 Definir colunas e concatenar\n",
    "    standing_cols_base = ['raceId', 'driverId', 'constructorId', 'points', 'position', 'wins']\n",
    "\n",
    "    df_driver_standings_sub = df_driver_standings.reindex(columns=standing_cols_base + ['driverStandingsId']).rename(\n",
    "        columns={'driverStandingsId': 'standing_brz_id'}\n",
    "    )\n",
    "    df_constructor_standings_sub = df_constructor_standings.reindex(columns=standing_cols_base + ['constructorStandingsId']).rename(\n",
    "        columns={'constructorStandingsId': 'standing_brz_id'}\n",
    "    )\n",
    "    \n",
    "    df_fato_posicoes = pd.concat([\n",
    "        df_driver_standings_sub, \n",
    "        df_constructor_standings_sub\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    # 2.4 Renomeação e Mapeamento para o Fato Silver (Seguindo o MER)\n",
    "    df_fato_posicoes = df_fato_posicoes.rename(columns={\n",
    "        'raceId': '#corrida_sk',\n",
    "        'driverId': '#piloto_sk',\n",
    "        'constructorId': '#construtor_sk',\n",
    "        'points': 'total_pontos',\n",
    "        'position': 'posicao_campeonato',\n",
    "        'wins': 'total_vitorias',\n",
    "        'standing_brz_id': 'standing_brz_id_auditoria'\n",
    "    })\n",
    "    \n",
    "    # Conversão de tipos numéricos\n",
    "    numeric_standing_cols = ['total_pontos', 'posicao_campeonato', 'total_vitorias']\n",
    "    for col in numeric_standing_cols:\n",
    "        df_fato_posicoes[col] = pd.to_numeric(df_fato_posicoes[col], errors='coerce')\n",
    "\n",
    "    # 2.5 Adicionar chave substituta (SK)\n",
    "    df_fato_posicoes['posicao_sk'] = range(1, len(df_fato_posicoes) + 1)\n",
    "    \n",
    "    # 2.6 Selecionar e reordenar colunas finais para o Fato\n",
    "    FATO_PONTUACAO_COLS = [\n",
    "        'posicao_sk', '#corrida_sk', '#piloto_sk', '#construtor_sk', \n",
    "        'total_pontos', 'posicao_campeonato', 'total_vitorias', \n",
    "        'standing_brz_id_auditoria'\n",
    "    ]\n",
    "    df_fato_posicoes = df_fato_posicoes[[col for col in FATO_PONTUACAO_COLS if col in df_fato_posicoes.columns]].copy()\n",
    "    \n",
    "    \n",
    "    # 2.7 Armazenamento na Camada Silver (Dicionário)\n",
    "    # Define df_silver globalmente para a próxima célula funcionar\n",
    "    if 'df_silver' not in locals():\n",
    "        df_silver = {} \n",
    "    df_silver['fato_resultados_corrida'] = df_fato_resultados\n",
    "    df_silver['fato_pontuacao_campeonato'] = df_fato_posicoes\n",
    "\n",
    "    print(\"\\n--- Criação das Tabelas Fato da Camada Silver Concluída ---\")\n",
    "    print(f\"FATO_RESULTADOS_CORRIDA: {len(df_silver['fato_resultados_corrida'])} registros\")\n",
    "    print(f\"FATO_PONTUACAO_CAMPEONATO: {len(df_silver['fato_pontuacao_campeonato'])} registros\")\n",
    "    print(\"Os DataFrames estão disponíveis no dicionário 'df_silver'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63c19550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FATO_RESULTADOS_CORRIDA (.head()) ---\n",
      "   resultado_sk #corrida_sk #piloto_sk #construtor_sk #status_sk  \\\n",
      "0             1          18          1              1          1   \n",
      "1             2          18          2              2          1   \n",
      "2             3          18          3              3          1   \n",
      "3             4          18          4              4          1   \n",
      "4             5          18          5              1          1   \n",
      "\n",
      "   #qualificacao_sk  #grid  #rank  pontos  posicao_final_ordenada  \\\n",
      "0               1.0      1    2.0    10.0                       1   \n",
      "1               5.0      5    3.0     8.0                       2   \n",
      "2               7.0      7    5.0     6.0                       3   \n",
      "3              12.0     11    7.0     5.0                       4   \n",
      "4               3.0      3    1.0     4.0                       5   \n",
      "\n",
      "   voltas_completadas  tempo_total_ms  volta_mais_rapida  velocidade_maxima  \\\n",
      "0                  58       5690616.0               39.0            218.300   \n",
      "1                  58       5696094.0               41.0            217.586   \n",
      "2                  58       5698779.0               41.0            216.719   \n",
      "3                  58       5707797.0               58.0            215.464   \n",
      "4                  58       5708630.0               43.0            218.385   \n",
      "\n",
      "   is_sprint  resultado_brz_id_auditoria  \n",
      "0          0                           1  \n",
      "1          0                           2  \n",
      "2          0                           3  \n",
      "3          0                           4  \n",
      "4          0                           5  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- FATO_RESULTADOS_CORRIDA (.head()) ---\")\n",
    "print(df_silver['fato_resultados_corrida'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f867bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FATO_POSICOES_CAMPEONATO (.head()) ---\n",
      "   standing_brz_id race_id_brz driver_id_brz constructor_id_brz  total_pontos  \\\n",
      "0                1          18             1                NaN          10.0   \n",
      "1                2          18             2                NaN           8.0   \n",
      "2                3          18             3                NaN           6.0   \n",
      "3                4          18             4                NaN           5.0   \n",
      "4                5          18             5                NaN           4.0   \n",
      "\n",
      "   posicao_campeonato_rank  total_vitorias tipo_standing  \\\n",
      "0                        1               1        PILOTO   \n",
      "1                        2               0        PILOTO   \n",
      "2                        3               0        PILOTO   \n",
      "3                        4               0        PILOTO   \n",
      "4                        5               0        PILOTO   \n",
      "\n",
      "  posicao_campeonato_texto  posicao_sk  \n",
      "0                        1           1  \n",
      "1                        2           2  \n",
      "2                        3           3  \n",
      "3                        4           4  \n",
      "4                        5           5  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- FATO_POSICOES_CAMPEONATO (.head()) ---\")\n",
    "print(df_silver['fato_posicoes_campeonato'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7f632b",
   "metadata": {},
   "source": [
    "___\n",
    "## Iniciando as Tabelas Dimensões\n",
    "\n",
    "Esta etapa da Camada Silver foca na desnormalização das tabelas mestras da Camada Bronze em entidades dimensionais otimizadas. O processo envolve a criação de Chaves Substitutas (`_sk_`) como chaves primárias para todas as dimensões (`DIM_STATUS`, `DIM_CIRCUITO`, `DIM_PILOTO`, etc.), a renomeação de atributos para o português e a garantia da unicidade e integridade dos registros. As chaves naturais originais são preservadas como atributos de auditoria, preparando as dimensões para o join eficiente com as tabelas fato e para a construção final do Modelo Dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d203de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO CRIAÇÃO DAS TABELAS DIMENSÃO ---\n",
      "1. Criando DIM_STATUS...\n",
      "2. Criando DIM_CIRCUITO...\n",
      "3. Criando DIM_CONSTRUTOR...\n",
      "4. Criando DIM_PILOTO...\n",
      "5. Criando DIM_QUALIFICACAO...\n",
      "6. Criando DIM_CORRIDA...\n"
     ]
    }
   ],
   "source": [
    "# Verificar se o dicionário df_bronze foi carregado corretamente.\n",
    "if 'df_bronze' not in locals() or not df_bronze:\n",
    "    print(\"ERRO: O dicionário 'df_bronze' não foi encontrado ou está vazio. Por favor, execute a célula de carregamento da Camada Bronze primeiro.\")\n",
    "else:\n",
    "    if 'df_silver' not in locals():\n",
    "        df_silver = {}\n",
    "        \n",
    "    print(\"--- INICIANDO CRIAÇÃO DAS TABELAS DIMENSÃO ---\")\n",
    "\n",
    "    # --- 1. DIM_STATUS ---\n",
    "    print(\"1. Criando DIM_STATUS...\")\n",
    "    df_status = df_bronze['status'].copy()\n",
    "    df_status = df_status.rename(columns={\n",
    "        'statusId': '#statusId',\n",
    "        'status': 'descricao_status'\n",
    "    })\n",
    "    df_status['_status_sk_'] = range(1, len(df_status) + 1)\n",
    "    df_status = df_status[['_status_sk_', '#statusId', 'descricao_status']].copy()\n",
    "    df_silver['dim_status'] = df_status\n",
    "\n",
    "    # --- 2. DIM_CIRCUITO ---\n",
    "    print(\"2. Criando DIM_CIRCUITO...\")\n",
    "    df_circuitos = df_bronze['circuits'].copy()\n",
    "    df_circuitos = df_circuitos.rename(columns={\n",
    "        'circuitId': '#circuitId',\n",
    "        'name': 'nome',\n",
    "        'location': 'localidade',\n",
    "        'country': 'país',\n",
    "        'lat': 'latitude',\n",
    "        'lng': 'longitude',\n",
    "        'alt': 'altitude'\n",
    "    }).drop(columns=['circuitRef', 'url'])\n",
    "\n",
    "    numeric_cols_circuito = ['latitude', 'longitude', 'altitude']\n",
    "    for col in numeric_cols_circuito:\n",
    "        df_circuitos[col] = pd.to_numeric(df_circuitos[col], errors='coerce')\n",
    "\n",
    "    df_circuitos['_circuito_sk_'] = range(1, len(df_circuitos) + 1)\n",
    "    df_circuitos = df_circuitos[['_circuito_sk_', '#circuitId', 'nome', 'localidade', 'país', 'latitude', 'longitude', 'altitude']].copy()\n",
    "    df_silver['dim_circuito'] = df_circuitos\n",
    "\n",
    "    # --- 3. DIM_CONSTRUTOR ---\n",
    "    print(\"3. Criando DIM_CONSTRUTOR...\")\n",
    "    df_construtor = df_bronze['constructors'].copy()\n",
    "    df_construtor = df_construtor.rename(columns={\n",
    "        'constructorId': '#constructorId',\n",
    "        'name': 'nome',\n",
    "        'nationality': 'nacionalidade'\n",
    "    }).drop(columns=['constructorRef', 'url'])\n",
    "    \n",
    "    df_construtor['_constructor_sk_'] = range(1, len(df_construtor) + 1)\n",
    "    df_construtor = df_construtor[['_constructor_sk_', '#constructorId', 'nome', 'nacionalidade']].copy()\n",
    "    df_silver['dim_construtor'] = df_construtor\n",
    "    \n",
    "    # --- 4. DIM_PILOTO ---\n",
    "    print(\"4. Criando DIM_PILOTO...\")\n",
    "    df_piloto = df_bronze['drivers'].copy()\n",
    "    \n",
    "    df_piloto = df_piloto.rename(columns={\n",
    "        'driverId': '#driverId',\n",
    "        'forename': 'nome',\n",
    "        'surname': 'sobrenome',\n",
    "        'dob': 'data_nascimento',\n",
    "        'nationality': 'nacionalidade',\n",
    "        'code': 'codigo'\n",
    "    }).drop(columns=['driverRef', 'number', 'url'])\n",
    "\n",
    "    df_piloto['nome_completo'] = df_piloto['nome'] + ' ' + df_piloto['sobrenome']  \n",
    "    df_piloto['data_nascimento'] = pd.to_datetime(df_piloto['data_nascimento'], errors='coerce')\n",
    "    df_piloto['_piloto_sk_'] = range(1, len(df_piloto) + 1)\n",
    "    df_piloto = df_piloto[['_piloto_sk_', '#driverId', 'nome', 'sobrenome', 'data_nascimento', 'nacionalidade', 'codigo']].copy()\n",
    "    df_silver['dim_piloto'] = df_piloto\n",
    "\n",
    "    # --- 5. DIM_QUALIFICACAO ---\n",
    "    print(\"5. Criando DIM_QUALIFICACAO...\")\n",
    "    df_qualificacao = df_bronze['qualifying'].copy()\n",
    "    \n",
    "    df_qualificacao = df_qualificacao.rename(columns={\n",
    "        'qualifyId': '#qualifyId',\n",
    "        'raceId': '#raceId',\n",
    "        'driverId': '#driverId',\n",
    "        'position': 'posicao_grid',\n",
    "        'q1': 'tempo_q1',\n",
    "        'q2': 'tempo_q2',\n",
    "        'q3': 'tempo_q3'\n",
    "    }).drop(columns=['constructorId', 'number'])\n",
    "\n",
    "    df_qualificacao['posicao_grid'] = pd.to_numeric(df_qualificacao['posicao_grid'], errors='coerce')\n",
    "\n",
    "    df_qualificacao['_qualificacao_sk_'] = range(1, len(df_qualificacao) + 1)\n",
    "    df_qualificacao = df_qualificacao[['_qualificacao_sk_', '#qualifyId', '#raceId', '#driverId', 'posicao_grid', 'tempo_q1', 'tempo_q2', 'tempo_q3']].copy()\n",
    "    df_silver['dim_qualificacao'] = df_qualificacao\n",
    "    \n",
    "    # --- 6. DIM_CORRIDA (Com Snowflake para CIRCUITO) ---\n",
    "    print(\"6. Criando DIM_CORRIDA...\")\n",
    "    df_corrida = df_bronze['races'].copy()\n",
    "    \n",
    "    # 6.1 Tratamento de data/hora\n",
    "    df_corrida['date'] = pd.to_datetime(df_corrida['date'], errors='coerce')\n",
    "    \n",
    "    # 6.2 Determinação do tipo de evento (Simplificada)\n",
    "    df_corrida['tipo_evento'] = 'GP'\n",
    "    df_corrida.loc[df_corrida['sprint_date'].notna() | df_corrida['sprint_time'].notna(), 'tipo_evento'] = 'SPRINT_WEEKEND'\n",
    "    \n",
    "    df_corrida = pd.merge(\n",
    "        df_corrida,\n",
    "        df_silver['dim_circuito'][['#circuitId', '_circuito_sk_']],\n",
    "        left_on='circuitId',\n",
    "        right_on='#circuitId',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    df_corrida = df_corrida.drop(columns=['#circuitId'])\n",
    "\n",
    "    # 6.3 Renomeação e Limpeza\n",
    "    df_corrida = df_corrida.rename(columns={\n",
    "        'raceId': '#raceId',\n",
    "        'circuitId': 'circuitId_brz', # Mantém a chave natural do circuito para auditoria\n",
    "        'year': 'ano',\n",
    "        'round': 'rodada',\n",
    "        'name': 'nome_gp',\n",
    "        'date': 'data_gp',\n",
    "        '_circuito_sk_': '#circuito_sk' # Chave estrangeira Snowflake\n",
    "    }).drop(columns=[c for c in df_corrida.columns if c.startswith(('fp1', 'fp2', 'fp3', 'quali', 'sprint', 'time', 'url'))])\n",
    "\n",
    "    df_corrida['_corrida_sk_'] = range(1, len(df_corrida) + 1)\n",
    "    df_corrida = df_corrida[['_corrida_sk_', '#raceId', '#circuito_sk', 'ano', 'rodada', 'nome_gp', 'data_gp', 'tipo_evento']].copy()\n",
    "    df_silver['dim_corrida'] = df_corrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DIM_PILOTO (.head()) ---\n",
      "   _piloto_sk_ #driverId      nome   sobrenome data_nascimento nacionalidade  \\\n",
      "0            1         1     Lewis    Hamilton      1985-01-07       British   \n",
      "1            2         2      Nick    Heidfeld      1977-05-10        German   \n",
      "2            3         3      Nico     Rosberg      1985-06-27        German   \n",
      "3            4         4  Fernando      Alonso      1981-07-29       Spanish   \n",
      "4            5         5    Heikki  Kovalainen      1981-10-19       Finnish   \n",
      "\n",
      "  codigo  \n",
      "0    HAM  \n",
      "1    HEI  \n",
      "2    ROS  \n",
      "3    ALO  \n",
      "4    KOV  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- DIM_PILOTO (.head()) ---\")\n",
    "print(df_silver['dim_piloto'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101bcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DIM_CORRIDA (.head()) ---\n",
      "   _corrida_sk_ #raceId  #circuito_sk   ano  rodada                nome_gp  \\\n",
      "0             1       1             1  2009       1  Australian Grand Prix   \n",
      "1             2       2             2  2009       2   Malaysian Grand Prix   \n",
      "2             3       3            17  2009       3     Chinese Grand Prix   \n",
      "3             4       4             3  2009       4     Bahrain Grand Prix   \n",
      "4             5       5             4  2009       5     Spanish Grand Prix   \n",
      "\n",
      "     data_gp tipo_evento  \n",
      "0 2009-03-29          GP  \n",
      "1 2009-04-05          GP  \n",
      "2 2009-04-19          GP  \n",
      "3 2009-04-26          GP  \n",
      "4 2009-05-10          GP  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- DIM_CORRIDA (.head()) ---\")\n",
    "print(df_silver['dim_corrida'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c46a4d",
   "metadata": {},
   "source": [
    "___\n",
    "## Salvando os dados \n",
    "\n",
    "Nesta etapa, as tabelas Fato e Dimensão que foram criadas e estruturadas em DataFrames do Pandas na Camada Silver serão persistidas. Cada DataFrame será exportado para um arquivo CSV único, utilizando o ponto e vírgula (;) como separador e garantindo a codificação UTF-8 para preservar acentuações e caracteres especiais. O atributo de índice de linha do Pandas será descartado para manter os arquivos limpos e alinhados com a estrutura de tabelas relacionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf91803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Materialização das Tabelas Silver para CSV ---\n",
      "Materializado: 'fato_resultados_corrida.csv' -> 27119 registros.\n",
      "Materializado: 'fato_posicoes_campeonato.csv' -> 48254 registros.\n",
      "Materializado: 'fato_pontuacao_campeonato.csv' -> 48254 registros.\n",
      "Materializado: 'dim_status.csv' -> 139 registros.\n",
      "Materializado: 'dim_circuito.csv' -> 77 registros.\n",
      "Materializado: 'dim_construtor.csv' -> 212 registros.\n",
      "Materializado: 'dim_piloto.csv' -> 861 registros.\n",
      "Materializado: 'dim_qualificacao.csv' -> 10494 registros.\n",
      "Materializado: 'dim_corrida.csv' -> 1125 registros.\n",
      "\n",
      "--- Materialização da Camada Silver Concluída ---\n"
     ]
    }
   ],
   "source": [
    "BASE_SILVER_PATH = '../data/silver/'\n",
    "\n",
    "if 'df_silver' not in locals() or not df_silver:\n",
    "    print(\"ERRO: O dicionário 'df_silver' não foi encontrado ou está vazio. Por favor, execute as células de criação das tabelas Fato e Dimensão.\")\n",
    "else:\n",
    "    print(\"\\n--- Iniciando Materialização das Tabelas Silver para CSV ---\")\n",
    "\n",
    "    for table_name, df in df_silver.items():\n",
    "        file_path = os.path.join(BASE_SILVER_PATH, f\"{table_name}.csv\")\n",
    "        \n",
    "        # Salva o DataFrame como um arquivo CSV\n",
    "        df.to_csv(\n",
    "            file_path,\n",
    "            index=False,        # Não salva o índice do DataFrame\n",
    "            sep=';',            # Usa ponto e vírgula como separador\n",
    "            encoding='utf-8'    # Garante a codificação correta\n",
    "        )\n",
    "        print(f\"Materializado: '{table_name}.csv' -> {len(df)} registros.\")\n",
    "\n",
    "    print(\"\\n--- Materialização da Camada Silver Concluída ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
